{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing your Parquet files\n",
    "directory_path = 'C:/Users/comma/Github/workspace/sas-access-samples/SAS Foundation/parquetdataset/'\n",
    "\n",
    "# Use glob to find all Parquet files in the directory\n",
    "parquet_file_paths = glob.glob(directory_path + '*.parquet')\n",
    "\n",
    "# Initialize an empty dictoionary to store the DataFrames\n",
    "dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode bytes to string if the value is a byte literal\n",
    "def decode_bytes(val):\n",
    "    if isinstance(val, bytes):\n",
    "        return val.decode('utf-8')\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the file paths\n",
    "for path in parquet_file_paths:\n",
    "    # Extract the base file name without the extension as the dictionary key\n",
    "    file_name = path.split('/')[-1].replace('.parquet', '')\n",
    "    \n",
    "    # Read each file into a DataFrame\n",
    "    df = pd.read_parquet(path)\n",
    "    \n",
    "    # Apply the decode_bytes function to each column using Series.map\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].map(decode_bytes)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with the file name as the key\n",
    "    dfs[file_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfs['parquetdataset\\\\samdat1']\n",
    "df2 = dfs['parquetdataset\\\\samdat2']\n",
    "df3 = dfs['parquetdataset\\\\samdat3']\n",
    "df4 = dfs['parquetdataset\\\\samdat4']\n",
    "df5 = dfs['parquetdataset\\\\samdat5']\n",
    "df6 = dfs['parquetdataset\\\\samdat6']\n",
    "df7 = dfs['parquetdataset\\\\samdat7']\n",
    "df8 = dfs['parquetdataset\\\\samdat8']\n",
    "df9 = dfs['parquetdataset\\\\samdat9']\n",
    "df10 = dfs['parquetdataset\\\\samdat10']\n",
    "df11 = dfs['parquetdataset\\\\samdat11']\n",
    "df12 = dfs['parquetdataset\\\\samdat12']\n",
    "df13 = dfs['parquetdataset\\\\samdat13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   FLIGHT    46 non-null     object        \n",
      " 1   DATES     46 non-null     datetime64[ns]\n",
      " 2   DEPART    46 non-null     float64       \n",
      " 3   ORIG      46 non-null     object        \n",
      " 4   DEST      46 non-null     object        \n",
      " 5   MILES     46 non-null     float64       \n",
      " 6   BOARDED   46 non-null     float64       \n",
      " 7   CAPACITY  46 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(3)\n",
      "memory usage: 3.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   FLIGHT    46 non-null     object        \n",
      " 1   DATES     46 non-null     datetime64[ns]\n",
      " 2   ORIG      46 non-null     object        \n",
      " 3   DEST      46 non-null     object        \n",
      " 4   DELAYCAT  46 non-null     object        \n",
      " 5   DESTYPE   46 non-null     object        \n",
      " 6   DELAY     46 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(5)\n",
      "memory usage: 2.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   FLIGHT   26 non-null     object        \n",
      " 1   DATES    26 non-null     datetime64[ns]\n",
      " 2   DEST     26 non-null     object        \n",
      " 3   BOARDED  26 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 964.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   FLIGHT  156 non-null    object        \n",
      " 1   DATES   156 non-null    datetime64[ns]\n",
      " 2   DEST    156 non-null    object        \n",
      " 3   IDNUM   156 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 5.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   IDNUM    148 non-null    object        \n",
      " 1   SEX      148 non-null    object        \n",
      " 2   JOBCODE  148 non-null    object        \n",
      " 3   SALARY   148 non-null    float64       \n",
      " 4   BIRTH    148 non-null    datetime64[ns]\n",
      " 5   HIRED    148 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(3)\n",
      "memory usage: 7.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   IDNUM    12 non-null     object        \n",
      " 1   SEX      12 non-null     object        \n",
      " 2   JOBCODE  12 non-null     object        \n",
      " 3   SALARY   12 non-null     float64       \n",
      " 4   BIRTH    12 non-null     datetime64[ns]\n",
      " 5   HIRED    12 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(3)\n",
      "memory usage: 708.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   IDNUM   148 non-null    object\n",
      " 1   LNAME   148 non-null    object\n",
      " 2   FNAME   148 non-null    object\n",
      " 3   CITY    148 non-null    object\n",
      " 4   STATE   148 non-null    object\n",
      " 5   HPHONE  148 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 7.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   SUPID   19 non-null     object\n",
      " 1   STATE   19 non-null     object\n",
      " 2   JOBCAT  19 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 588.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   INVNUM    17 non-null     float64       \n",
      " 1   BILLEDTO  17 non-null     object        \n",
      " 2   AMTBILL   17 non-null     float64       \n",
      " 3   COUNTRY   17 non-null     object        \n",
      " 4   AMTINUS   17 non-null     float64       \n",
      " 5   BILLEDBY  17 non-null     float64       \n",
      " 6   BILLEDON  17 non-null     datetime64[ns]\n",
      " 7   PAIDON    10 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(4), object(2)\n",
      "memory usage: 1.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   EMPID     22 non-null     float64       \n",
      " 1   HIREDATE  22 non-null     datetime64[ns]\n",
      " 2   SALARY    21 non-null     float64       \n",
      " 3   DEPT      22 non-null     object        \n",
      " 4   JOBCODE   22 non-null     float64       \n",
      " 5   GENDER    21 non-null     object        \n",
      " 6   BIRTHDTE  21 non-null     datetime64[ns]\n",
      " 7   LASTNAME  22 non-null     object        \n",
      " 8   FRSTNAME  22 non-null     object        \n",
      " 9   MIDNAME   22 non-null     object        \n",
      " 10  PHONE     21 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(3), object(6)\n",
      "memory usage: 2.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   CUSTOMER  21 non-null     object        \n",
      " 1   STATE     11 non-null     object        \n",
      " 2   ZIPCODE   15 non-null     object        \n",
      " 3   COUNTRY   20 non-null     object        \n",
      " 4   PHONE     21 non-null     object        \n",
      " 5   NAME      20 non-null     object        \n",
      " 6   CONTACT   19 non-null     object        \n",
      " 7   ADDRESS   20 non-null     object        \n",
      " 8   CITY      20 non-null     object        \n",
      " 9   FIRSTORD  21 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 1.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   ORDERNUM  38 non-null     float64       \n",
      " 1   STOCKNUM  38 non-null     float64       \n",
      " 2   LENGTH    38 non-null     float64       \n",
      " 3   FABCHARG  24 non-null     float64       \n",
      " 4   SHIPTO    38 non-null     object        \n",
      " 5   DATEORD   38 non-null     datetime64[ns]\n",
      " 6   SHIPPED   15 non-null     datetime64[ns]\n",
      " 7   TAKENBY   38 non-null     float64       \n",
      " 8   PROCSBY   15 non-null     float64       \n",
      " 9   SPECFLAG  10 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(6), object(2)\n",
      "memory usage: 3.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   EMPID     6 non-null      float64       \n",
      " 1   HIREDATE  6 non-null      datetime64[ns]\n",
      " 2   DEPT      6 non-null      object        \n",
      " 3   GENDER    5 non-null      object        \n",
      " 4   LASTNAME  6 non-null      object        \n",
      " 5   FIRSTNAM  6 non-null      object        \n",
      " 6   MIDDLENA  5 non-null      object        \n",
      " 7   FAMILYID  2 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(5)\n",
      "memory usage: 516.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df1.info()\n",
    "df2.info()\n",
    "df3.info()\n",
    "df4.info()\n",
    "df5.info()\n",
    "df6.info()\n",
    "df7.info()\n",
    "df8.info()\n",
    "df9.info()\n",
    "df10.info()\n",
    "df11.info()\n",
    "df12.info()\n",
    "df13.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 1: New Jersey Phone List\n",
      "         LNAME    FNAME STATE        HPHONE\n",
      "17      RHODES   JEREMY    NJ  201/812-1837\n",
      "62     ALVAREZ   CARLOS    NJ  201/732-8787\n",
      "66       DACKO    JASON    NJ  201/732-2323\n",
      "69   HENDERSON  WILLIAM    NJ  201/812-4789\n",
      "72     JOHNSON  JACKSON    NJ  201/732-3678\n",
      "73     MURPHEY     JOHN    NJ  201/812-4414\n",
      "74      PETERS  RANDALL    NJ  201/812-2478\n",
      "77     NEWKIRK  WILLIAM    NJ  201/732-6611\n",
      "79       ROUSE   JEREMY    NJ  201/732-9834\n",
      "81    FUJIHARA    KYOKO    NJ  201/812-0902\n",
      "85        VICK  THERESA    NJ  201/812-2424\n",
      "92      YANCEY    ROBIN    NJ  201/812-1874\n",
      "100   LAWRENCE    KATHY    NJ  201/812-3337\n",
      "101    NEWKIRK   SANDRA    NJ  201/812-3331\n",
      "109   BAREFOOT   JOSEPH    NJ  201/812-5665\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15 entries, 17 to 109\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   LNAME   15 non-null     object\n",
      " 1   FNAME   15 non-null     object\n",
      " 2   STATE   15 non-null     object\n",
      " 3   HPHONE  15 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 600.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "## Sample #1\n",
    "\n",
    "# Filter the DataFrame for rows where state is 'NJ' and select specific columns\n",
    "filtered_df7 = df7[df7['STATE'] == 'NJ'][['LNAME', 'FNAME', 'STATE', 'HPHONE']]\n",
    "\n",
    "# Display the title\n",
    "print('Libname Sample 1: New Jersey Phone List')\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df7)\n",
    "filtered_df7.info()\n",
    "\n",
    "#row_count=filtered_df7.shape[0]\n",
    "#column_count=filtered_df7.shape[1]\n",
    "#print(\"No.of rows: \", row_count)\n",
    "#print(\"No.of columns: \", column_count)\n",
    "#print(\"Column names:\", filtered_df7.columns.tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IDNUM JOBCODE      SALARY CATEGORY\n",
      "0    1009     TA1  $28,880.00      Low\n",
      "1    1017     TA3  $40,858.00      Avg\n",
      "2    1036     TA3  $39,392.00      Avg\n",
      "3    1037     TA1  $28,558.00      Low\n",
      "4    1038     TA1  $26,533.00      Low\n",
      "..    ...     ...         ...      ...\n",
      "143  1970     FA1  $22,615.00      Low\n",
      "144  1983     FA3  $33,419.00      Avg\n",
      "145  1988     FA3  $32,217.00      Avg\n",
      "146  1991     TA1  $27,645.00      Low\n",
      "147  1995     ME1  $28,810.00      Low\n",
      "\n",
      "[148 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   IDNUM     148 non-null    object\n",
      " 1   JOBCODE   148 non-null    object\n",
      " 2   SALARY    148 non-null    object\n",
      " 3   CATEGORY  148 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sample #2\n",
    "\n",
    "# Drop the specified columns\n",
    "df_highwage = df5.drop(['SEX', 'BIRTH', 'HIRED'], axis=1)\n",
    "\n",
    "# Create the CATEGORY column based on conditions\n",
    "df_highwage['CATEGORY'] = np.where(df_highwage['SALARY'] > 60000, 'High',\n",
    "                                   np.where(df_highwage['SALARY'] < 30000, 'Low', 'Avg'))\n",
    "\n",
    "# Assuming SALARY is in uppercase, adjust formatting to currency style for display\n",
    "# Note: This conversion is purely for display purposes and converts the column to strings.\n",
    "df_highwage['SALARY'] = df_highwage['SALARY'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "print(df_highwage)\n",
    "df_highwage.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 3: Supervisor Information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>LNAME</th>\n",
       "      <th>FNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE_x</th>\n",
       "      <th>HPHONE</th>\n",
       "      <th>STATE_y</th>\n",
       "      <th>JOBCAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1106</td>\n",
       "      <td>MARSHBURN</td>\n",
       "      <td>JASPER</td>\n",
       "      <td>STAMFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/781-1457</td>\n",
       "      <td>CT</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1118</td>\n",
       "      <td>DENNIS</td>\n",
       "      <td>ROGER</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/383-1122</td>\n",
       "      <td>NY</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1126</td>\n",
       "      <td>KIMANI</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/586-1229</td>\n",
       "      <td>NY</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352</td>\n",
       "      <td>RIVERS</td>\n",
       "      <td>SIMON</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/383-3345</td>\n",
       "      <td>NY</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1385</td>\n",
       "      <td>RAYNOR</td>\n",
       "      <td>MILTON</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/675-2846</td>\n",
       "      <td>CT</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1401</td>\n",
       "      <td>ALVAREZ</td>\n",
       "      <td>CARLOS</td>\n",
       "      <td>PATERSON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/732-8787</td>\n",
       "      <td>NJ</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1405</td>\n",
       "      <td>DACKO</td>\n",
       "      <td>JASON</td>\n",
       "      <td>PATERSON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/732-2323</td>\n",
       "      <td>NJ</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1417</td>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PATERSON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/732-6611</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1420</td>\n",
       "      <td>ROUSE</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>PATERSON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/732-9834</td>\n",
       "      <td>NJ</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1431</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>DEBORAH</td>\n",
       "      <td>STAMFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/781-2987</td>\n",
       "      <td>CT</td>\n",
       "      <td>FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1433</td>\n",
       "      <td>YANCEY</td>\n",
       "      <td>ROBIN</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/812-1874</td>\n",
       "      <td>NJ</td>\n",
       "      <td>FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1442</td>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>SANDRA</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>201/812-3331</td>\n",
       "      <td>NJ</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1564</td>\n",
       "      <td>WALTERS</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/587-3257</td>\n",
       "      <td>NY</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1639</td>\n",
       "      <td>CARTER-COHEN</td>\n",
       "      <td>KAREN</td>\n",
       "      <td>STAMFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/781-8839</td>\n",
       "      <td>CT</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1677</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>JACKSON</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/675-7432</td>\n",
       "      <td>CT</td>\n",
       "      <td>BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1834</td>\n",
       "      <td>LEBLANC</td>\n",
       "      <td>RUSSELL</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-0040</td>\n",
       "      <td>NY</td>\n",
       "      <td>BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1882</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-0216</td>\n",
       "      <td>NY</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1935</td>\n",
       "      <td>FERNANDEZ</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/675-2962</td>\n",
       "      <td>CT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1983</td>\n",
       "      <td>DEAN</td>\n",
       "      <td>SHARON</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-1647</td>\n",
       "      <td>NY</td>\n",
       "      <td>FA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDNUM         LNAME    FNAME        CITY STATE_x        HPHONE STATE_y  \\\n",
       "0   1106     MARSHBURN   JASPER    STAMFORD      CT  203/781-1457      CT   \n",
       "1   1118        DENNIS    ROGER    NEW YORK      NY  718/383-1122      NY   \n",
       "2   1126        KIMANI     ANNE    NEW YORK      NY  212/586-1229      NY   \n",
       "3   1352        RIVERS    SIMON    NEW YORK      NY  718/383-3345      NY   \n",
       "4   1385        RAYNOR   MILTON  BRIDGEPORT      CT  203/675-2846      CT   \n",
       "5   1401       ALVAREZ   CARLOS    PATERSON      NJ  201/732-8787      NJ   \n",
       "6   1405         DACKO    JASON    PATERSON      NJ  201/732-2323      NJ   \n",
       "7   1417       NEWKIRK  WILLIAM    PATERSON      NJ  201/732-6611      NJ   \n",
       "8   1420         ROUSE   JEREMY    PATERSON      NJ  201/732-9834      NJ   \n",
       "9   1431         YOUNG  DEBORAH    STAMFORD      CT  203/781-2987      CT   \n",
       "10  1433        YANCEY    ROBIN   PRINCETON      NJ  201/812-1874      NJ   \n",
       "11  1442       NEWKIRK   SANDRA   PRINCETON      NJ  201/812-3331      NJ   \n",
       "12  1564       WALTERS     ANNE    NEW YORK      NY  212/587-3257      NY   \n",
       "13  1639  CARTER-COHEN    KAREN    STAMFORD      CT  203/781-8839      CT   \n",
       "14  1677        KRAMER  JACKSON  BRIDGEPORT      CT  203/675-7432      CT   \n",
       "15  1834       LEBLANC  RUSSELL    NEW YORK      NY  718/384-0040      NY   \n",
       "16  1882        TUCKER     ALAN    NEW YORK      NY  718/384-0216      NY   \n",
       "17  1935     FERNANDEZ  KATRINA  BRIDGEPORT      CT  203/675-2962      CT   \n",
       "18  1983          DEAN   SHARON    NEW YORK      NY  718/384-1647      NY   \n",
       "\n",
       "   JOBCAT  \n",
       "0      PT  \n",
       "1      PT  \n",
       "2      TA  \n",
       "3      NA  \n",
       "4      ME  \n",
       "5      TA  \n",
       "6      SC  \n",
       "7      NA  \n",
       "8      ME  \n",
       "9      FA  \n",
       "10     FA  \n",
       "11     PT  \n",
       "12     SC  \n",
       "13     TA  \n",
       "14     BC  \n",
       "15     BC  \n",
       "16     ME  \n",
       "17     NA  \n",
       "18     FA  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample #3\n",
    "\n",
    "# Rename the column in df8 for the merge\n",
    "df8_renamed = df8.rename(columns={'SUPID': 'IDNUM'})\n",
    "\n",
    "# Merge df7 and df8 on IDNUM, indicating records from df8 with the 'super' indicator\n",
    "combined = pd.merge(df7, df8_renamed, on='IDNUM', how='inner', indicator='super')\n",
    "\n",
    "# Filter to keep only the records from df8 (SAMDAT8)\n",
    "combined = combined[combined['super'] == 'both']\n",
    "\n",
    "# The 'super' column was used as an indicator. If not needed, you can drop it\n",
    "combined.drop('super', axis=1, inplace=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"Libname Sample 3: Supervisor Information\")\n",
    "combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>JOBCODE</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>BIRTH</th>\n",
       "      <th>HIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009</td>\n",
       "      <td>M</td>\n",
       "      <td>TA1</td>\n",
       "      <td>28880.0</td>\n",
       "      <td>1959-03-02</td>\n",
       "      <td>1992-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017</td>\n",
       "      <td>M</td>\n",
       "      <td>TA3</td>\n",
       "      <td>40858.0</td>\n",
       "      <td>1957-12-28</td>\n",
       "      <td>1981-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>F</td>\n",
       "      <td>TA3</td>\n",
       "      <td>39392.0</td>\n",
       "      <td>1965-05-19</td>\n",
       "      <td>1984-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1037</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>28558.0</td>\n",
       "      <td>1964-04-10</td>\n",
       "      <td>1992-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1038</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>26533.0</td>\n",
       "      <td>1969-11-09</td>\n",
       "      <td>1991-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1970</td>\n",
       "      <td>F</td>\n",
       "      <td>FA1</td>\n",
       "      <td>22615.0</td>\n",
       "      <td>1964-09-25</td>\n",
       "      <td>1991-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1983</td>\n",
       "      <td>F</td>\n",
       "      <td>FA3</td>\n",
       "      <td>33419.0</td>\n",
       "      <td>1962-02-28</td>\n",
       "      <td>1987-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1988</td>\n",
       "      <td>M</td>\n",
       "      <td>FA3</td>\n",
       "      <td>32217.0</td>\n",
       "      <td>1959-11-30</td>\n",
       "      <td>1984-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1991</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>1972-05-07</td>\n",
       "      <td>1992-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1995</td>\n",
       "      <td>F</td>\n",
       "      <td>ME1</td>\n",
       "      <td>28810.0</td>\n",
       "      <td>1973-08-24</td>\n",
       "      <td>1993-09-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDNUM SEX JOBCODE   SALARY      BIRTH      HIRED\n",
       "0    1009   M     TA1  28880.0 1959-03-02 1992-03-26\n",
       "1    1017   M     TA3  40858.0 1957-12-28 1981-10-16\n",
       "2    1036   F     TA3  39392.0 1965-05-19 1984-10-23\n",
       "3    1037   F     TA1  28558.0 1964-04-10 1992-09-13\n",
       "4    1038   F     TA1  26533.0 1969-11-09 1991-11-23\n",
       "..    ...  ..     ...      ...        ...        ...\n",
       "143  1970   F     FA1  22615.0 1964-09-25 1991-03-12\n",
       "144  1983   F     FA3  33419.0 1962-02-28 1987-04-27\n",
       "145  1988   M     FA3  32217.0 1959-11-30 1984-09-18\n",
       "146  1991   F     TA1  27645.0 1972-05-07 1992-12-12\n",
       "147  1995   F     ME1  28810.0 1973-08-24 1993-09-19\n",
       "\n",
       "[148 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   IDNUM    148 non-null    object        \n",
      " 1   SEX      148 non-null    object        \n",
      " 2   JOBCODE  148 non-null    object        \n",
      " 3   SALARY   148 non-null    float64       \n",
      " 4   BIRTH    148 non-null    datetime64[ns]\n",
      " 5   HIRED    148 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(3)\n",
      "memory usage: 7.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   IDNUM    12 non-null     object        \n",
      " 1   SEX      12 non-null     object        \n",
      " 2   JOBCODE  12 non-null     object        \n",
      " 3   SALARY   12 non-null     float64       \n",
      " 4   BIRTH    12 non-null     datetime64[ns]\n",
      " 5   HIRED    12 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(3)\n",
      "memory usage: 708.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df5.info()\n",
    "df6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 4: Updated Payroll Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>JOBCODE</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>BIRTH</th>\n",
       "      <th>HIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009</td>\n",
       "      <td>M</td>\n",
       "      <td>TA1</td>\n",
       "      <td>28880.0</td>\n",
       "      <td>1959-03-02</td>\n",
       "      <td>1992-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017</td>\n",
       "      <td>M</td>\n",
       "      <td>TA3</td>\n",
       "      <td>40858.0</td>\n",
       "      <td>1957-12-28</td>\n",
       "      <td>1981-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>F</td>\n",
       "      <td>TA3</td>\n",
       "      <td>42465.0</td>\n",
       "      <td>1965-05-19</td>\n",
       "      <td>1984-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1037</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>28558.0</td>\n",
       "      <td>1964-04-10</td>\n",
       "      <td>1992-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1038</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>26533.0</td>\n",
       "      <td>1969-11-09</td>\n",
       "      <td>1991-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1983</td>\n",
       "      <td>F</td>\n",
       "      <td>FA3</td>\n",
       "      <td>33419.0</td>\n",
       "      <td>1962-02-28</td>\n",
       "      <td>1987-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1988</td>\n",
       "      <td>M</td>\n",
       "      <td>FA3</td>\n",
       "      <td>32217.0</td>\n",
       "      <td>1959-11-30</td>\n",
       "      <td>1984-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1991</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>1972-05-07</td>\n",
       "      <td>1992-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1995</td>\n",
       "      <td>F</td>\n",
       "      <td>ME1</td>\n",
       "      <td>28810.0</td>\n",
       "      <td>1973-08-24</td>\n",
       "      <td>1993-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1998</td>\n",
       "      <td>M</td>\n",
       "      <td>SCP</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>1970-09-10</td>\n",
       "      <td>1992-11-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDNUM SEX JOBCODE   SALARY      BIRTH      HIRED\n",
       "0    1009   M     TA1  28880.0 1959-03-02 1992-03-26\n",
       "1    1017   M     TA3  40858.0 1957-12-28 1981-10-16\n",
       "2    1036   F     TA3  42465.0 1965-05-19 1984-10-23\n",
       "3    1037   F     TA1  28558.0 1964-04-10 1992-09-13\n",
       "4    1038   F     TA1  26533.0 1969-11-09 1991-11-23\n",
       "..    ...  ..     ...      ...        ...        ...\n",
       "145  1983   F     FA3  33419.0 1962-02-28 1987-04-27\n",
       "146  1988   M     FA3  32217.0 1959-11-30 1984-09-18\n",
       "147  1991   F     TA1  27645.0 1972-05-07 1992-12-12\n",
       "148  1995   F     ME1  28810.0 1973-08-24 1993-09-19\n",
       "149  1998   M     SCP  23100.0 1970-09-10 1992-11-02\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample #4 \n",
    "\n",
    "# First, ensure that IDNUM is the index, to align with SAS's by-statement functionality\n",
    "df5.set_index('IDNUM', inplace=True, drop=False)\n",
    "df6.set_index('IDNUM', inplace=True, drop=False)\n",
    "\n",
    "# Perform the update operation: for existing indexes, update df5's rows with df6's\n",
    "# Note: The combine_first method works by filling in missing values in df5 with values from df6\n",
    "# This is slightly different from SAS's update, which replaces values even if they are not missing\n",
    "# For a true \"update\" as SAS does (overwriting existing values), more complex logic is needed\n",
    "payroll = df6.combine_first(df5)\n",
    "\n",
    "# Reset the index to move IDNUM back to a column (if desired)\n",
    "payroll.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the title and the DataFrame\n",
    "print('Libname Sample 4: Updated Payroll Data')\n",
    "payroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 5: Total Salary by Jobcode\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobcode</th>\n",
       "      <th>Total for Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCK</td>\n",
       "      <td>$232,148.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FA1</td>\n",
       "      <td>$253,433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FA2</td>\n",
       "      <td>$447,790.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FA3</td>\n",
       "      <td>$230,537.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME1</td>\n",
       "      <td>$228,002.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ME2</td>\n",
       "      <td>$498,076.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ME3</td>\n",
       "      <td>$296,875.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NA1</td>\n",
       "      <td>$210,161.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NA2</td>\n",
       "      <td>$157,149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PT1</td>\n",
       "      <td>$543,264.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PT2</td>\n",
       "      <td>$879,252.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PT3</td>\n",
       "      <td>$221,009.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCP</td>\n",
       "      <td>$128,162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TA1</td>\n",
       "      <td>$249,492.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TA2</td>\n",
       "      <td>$671,499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TA3</td>\n",
       "      <td>$476,155.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jobcode Total for Group\n",
       "0      BCK     $232,148.00\n",
       "1      FA1     $253,433.00\n",
       "2      FA2     $447,790.00\n",
       "3      FA3     $230,537.00\n",
       "4      ME1     $228,002.00\n",
       "5      ME2     $498,076.00\n",
       "6      ME3     $296,875.00\n",
       "7      NA1     $210,161.00\n",
       "8      NA2     $157,149.00\n",
       "9      PT1     $543,264.00\n",
       "10     PT2     $879,252.00\n",
       "11     PT3     $221,009.00\n",
       "12     SCP     $128,162.00\n",
       "13     TA1     $249,492.00\n",
       "14     TA2     $671,499.00\n",
       "15     TA3     $476,155.00"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample #5\n",
    "\n",
    "# Group by JOBCODE and calculate the sum of SALARY for each group\n",
    "salary_totals = df5.groupby('JOBCODE')['SALARY'].sum().reset_index()\n",
    "\n",
    "# Rename columns to match SAS output\n",
    "salary_totals.columns = ['Jobcode', 'Total for Group']\n",
    "\n",
    "# Format the 'Total for Group' column as currency for display\n",
    "# Note: This converts the values to strings, so do this only for final display purposes\n",
    "salary_totals['Total for Group'] = salary_totals['Total for Group'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Libname Sample 5: Total Salary by Jobcode\")\n",
    "salary_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 6: Flights to London and Frankfurt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATES</th>\n",
       "      <th>DEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATES DEST\n",
       "3  1998-03-01  FRA\n",
       "10 1998-03-02  FRA\n",
       "17 1998-03-03  FRA\n",
       "24 1998-03-04  FRA\n",
       "31 1998-03-05  FRA\n",
       "42 1998-03-07  FRA\n",
       "2  1998-03-01  LON\n",
       "9  1998-03-02  LON\n",
       "16 1998-03-03  LON\n",
       "23 1998-03-04  LON\n",
       "30 1998-03-05  LON\n",
       "36 1998-03-06  LON\n",
       "41 1998-03-07  LON"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIBNAME Sample 6: Flights to London and Frankfurt\n",
    "\n",
    "# Assuming df2 corresponds to SAMDAT2 and is already loaded\n",
    "\n",
    "# Filter df2 for rows where DEST is 'FRA' (Frankfurt) or 'LON' (London)\n",
    "flights_filtered = df2[(df2['DEST'] == 'FRA') | (df2['DEST'] == 'LON')]\n",
    "\n",
    "# Order the results by DEST\n",
    "flights_sorted = flights_filtered.sort_values(by='DEST')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Libname Sample 6: Flights to London and Frankfurt\")\n",
    "flights_sorted[['DATES', 'DEST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 7: International Flights by Flight Number with Over 200 Passengers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>DATES</th>\n",
       "      <th>DEST</th>\n",
       "      <th>BOARDED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LON</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LON</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>FRA</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>FRA</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLIGHT      DATES DEST  BOARDED\n",
       "12    219 1998-03-04  LON    232.0\n",
       "22    219 1998-03-07  LON    241.0\n",
       "1     622 1998-03-01  FRA    207.0\n",
       "23    622 1998-03-07  FRA    210.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIBNAME Sample 7: International Flights by Flight Number with Over 200 Passengers\n",
    "\n",
    "# Filter df3 for flights with more than 200 passengers boarded\n",
    "flights_over_200 = df3[df3['BOARDED'] > 200]\n",
    "\n",
    "# Order the results by FLIGHT\n",
    "flights_sorted = flights_over_200.sort_values(by='FLIGHT')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Libname Sample 7: International Flights by Flight Number with Over 200 Passengers\")\n",
    "flights_sorted[['FLIGHT', 'DATES', 'DEST', 'BOARDED']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>LNAME</th>\n",
       "      <th>FNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>HPHONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/586-7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017</td>\n",
       "      <td>WELCH</td>\n",
       "      <td>DARIUS</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/586-5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>WONG</td>\n",
       "      <td>LESLIE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/587-2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1037</td>\n",
       "      <td>CHOW</td>\n",
       "      <td>JANE</td>\n",
       "      <td>STAMFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/781-8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1038</td>\n",
       "      <td>RODRIGUEZ</td>\n",
       "      <td>MARIA</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/675-2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1970</td>\n",
       "      <td>PARKER</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/383-3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1983</td>\n",
       "      <td>DEAN</td>\n",
       "      <td>SHARON</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1988</td>\n",
       "      <td>COOPER</td>\n",
       "      <td>ANTHONY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/587-1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1991</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>GRETCHEN</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>CT</td>\n",
       "      <td>203/675-0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1995</td>\n",
       "      <td>VARNER</td>\n",
       "      <td>ELIZABETH</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-7113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDNUM      LNAME      FNAME        CITY STATE        HPHONE\n",
       "0    1009     MORGAN     GEORGE    NEW YORK    NY  212/586-7753\n",
       "1    1017      WELCH     DARIUS    NEW YORK    NY  212/586-5535\n",
       "2    1036       WONG     LESLIE    NEW YORK    NY  212/587-2570\n",
       "3    1037       CHOW       JANE    STAMFORD    CT  203/781-8868\n",
       "4    1038  RODRIGUEZ      MARIA  BRIDGEPORT    CT  203/675-2048\n",
       "..    ...        ...        ...         ...   ...           ...\n",
       "143  1970     PARKER       ANNE    NEW YORK    NY  718/383-3895\n",
       "144  1983       DEAN     SHARON    NEW YORK    NY  718/384-1647\n",
       "145  1988     COOPER    ANTHONY    NEW YORK    NY  212/587-1228\n",
       "146  1991     HOWARD   GRETCHEN  BRIDGEPORT    CT  203/675-0007\n",
       "147  1995     VARNER  ELIZABETH    NEW YORK    NY  718/384-7113\n",
       "\n",
       "[148 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = dfs['parquetdataset\\\\samdat5']\n",
    "df6 = dfs['parquetdataset\\\\samdat6']\n",
    "df7 = dfs['parquetdataset\\\\samdat7']\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If IDNUM is a column, ensure it's not duplicated as an index\n",
    "df7 = df7.reset_index(drop=True)\n",
    "df5 = df5.reset_index(drop=True)\n",
    "\n",
    "# Merge DataFrames on 'IDNUM'\n",
    "merged_df = pd.merge(df7, df5, on='IDNUM', suffixes=('_a', '_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 8: Employees with salary greater than $40,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comma\\AppData\\Local\\Temp\\ipykernel_17776\\135138160.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  employees_over_40k['SALARY'] = employees_over_40k['SALARY'].apply(lambda x: f\"${x:,.2f}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNAME</th>\n",
       "      <th>FNAME</th>\n",
       "      <th>SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELCH</td>\n",
       "      <td>DARIUS</td>\n",
       "      <td>$40,858.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VENTER</td>\n",
       "      <td>RANDALL</td>\n",
       "      <td>$66,558.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MARSHBURN</td>\n",
       "      <td>JASPER</td>\n",
       "      <td>$89,632.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>THOMPSON</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>$89,977.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RHODES</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>$40,586.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DENNIS</td>\n",
       "      <td>ROGER</td>\n",
       "      <td>$111,379.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KIMANI</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>$40,899.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CASTON</td>\n",
       "      <td>FRANKLIN</td>\n",
       "      <td>$41,690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>STEPHENSON</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>$42,178.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BANADYGA</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>$88,606.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>O'NEAL</td>\n",
       "      <td>BRYAN</td>\n",
       "      <td>$40,079.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RIVERS</td>\n",
       "      <td>SIMON</td>\n",
       "      <td>$53,798.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MORGAN</td>\n",
       "      <td>ALFRED</td>\n",
       "      <td>$42,264.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RAYNOR</td>\n",
       "      <td>MILTON</td>\n",
       "      <td>$43,900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>COHEN</td>\n",
       "      <td>LEE</td>\n",
       "      <td>$91,376.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GREGORSKI</td>\n",
       "      <td>DANIEL</td>\n",
       "      <td>$68,096.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>HAVELKA</td>\n",
       "      <td>RAYMOND</td>\n",
       "      <td>$41,551.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>HARRIS</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>$84,685.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>$52,270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ROUSE</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>$43,071.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>BRADY</td>\n",
       "      <td>CHRISTINE</td>\n",
       "      <td>$68,767.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HASENHAUER</td>\n",
       "      <td>CHRISTINA</td>\n",
       "      <td>$70,736.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>SANDRA</td>\n",
       "      <td>$84,536.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>WELLS</td>\n",
       "      <td>AGNES</td>\n",
       "      <td>$42,274.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NEWTON</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>$84,203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BAREFOOT</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>$43,025.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>PARKER</td>\n",
       "      <td>JAY</td>\n",
       "      <td>$41,526.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>HERRERO</td>\n",
       "      <td>CLYDE</td>\n",
       "      <td>$66,130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>PENNINGTON</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>$71,349.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>CARTER-COHEN</td>\n",
       "      <td>KAREN</td>\n",
       "      <td>$40,260.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>BRANCACCIO</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>$66,517.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>LUFKIN</td>\n",
       "      <td>ROY</td>\n",
       "      <td>$109,630.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>TRIPP</td>\n",
       "      <td>KATHY</td>\n",
       "      <td>$84,471.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NORRIS</td>\n",
       "      <td>DIANE</td>\n",
       "      <td>$43,433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>TUCKER</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>$41,538.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>STEPHENSON</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>$91,908.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>GRAHAM</td>\n",
       "      <td>ALVIN</td>\n",
       "      <td>$65,111.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>UPCHURCH</td>\n",
       "      <td>LARRY</td>\n",
       "      <td>$89,858.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>FERNANDEZ</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>$51,081.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LNAME      FNAME       SALARY\n",
       "1           WELCH     DARIUS   $40,858.00\n",
       "7          VENTER    RANDALL   $66,558.00\n",
       "15      MARSHBURN     JASPER   $89,632.00\n",
       "16       THOMPSON      WAYNE   $89,977.00\n",
       "17         RHODES     JEREMY   $40,586.00\n",
       "24         DENNIS      ROGER  $111,379.00\n",
       "32         KIMANI       ANNE   $40,899.00\n",
       "45         CASTON   FRANKLIN   $41,690.00\n",
       "47     STEPHENSON       ADAM   $42,178.00\n",
       "48       BANADYGA     JUSTIN   $88,606.00\n",
       "49         O'NEAL      BRYAN   $40,079.00\n",
       "51         RIVERS      SIMON   $53,798.00\n",
       "56         MORGAN     ALFRED   $42,264.00\n",
       "58         RAYNOR     MILTON   $43,900.00\n",
       "65          COHEN        LEE   $91,376.00\n",
       "68      GREGORSKI     DANIEL   $68,096.00\n",
       "70        HAVELKA    RAYMOND   $41,551.00\n",
       "71         HARRIS    CHARLES   $84,685.00\n",
       "77        NEWKIRK    WILLIAM   $52,270.00\n",
       "79          ROUSE     JEREMY   $43,071.00\n",
       "87          BRADY  CHRISTINE   $68,767.00\n",
       "98     HASENHAUER  CHRISTINA   $70,736.00\n",
       "101       NEWKIRK     SANDRA   $84,536.00\n",
       "102         WELLS      AGNES   $42,274.00\n",
       "106        NEWTON      JAMES   $84,203.00\n",
       "109      BAREFOOT     JOSEPH   $43,025.00\n",
       "110        PARKER        JAY   $41,526.00\n",
       "111       HERRERO      CLYDE   $66,130.00\n",
       "113    PENNINGTON    MICHAEL   $71,349.00\n",
       "118  CARTER-COHEN      KAREN   $40,260.00\n",
       "125    BRANCACCIO     JOSEPH   $66,517.00\n",
       "126        LUFKIN        ROY  $109,630.00\n",
       "129         TRIPP      KATHY   $84,471.00\n",
       "131        NORRIS      DIANE   $43,433.00\n",
       "134        TUCKER       ALAN   $41,538.00\n",
       "135    STEPHENSON     ROBERT   $91,908.00\n",
       "137        GRAHAM      ALVIN   $65,111.00\n",
       "141      UPCHURCH      LARRY   $89,858.00\n",
       "142     FERNANDEZ    KATRINA   $51,081.00"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIBNAME Sample 8: Employees with salary greater than $40,000\n",
    "\n",
    "# If IDNUM is a column, ensure it's not duplicated as an index\n",
    "df7 = df7.reset_index(drop=True)\n",
    "df5 = df5.reset_index(drop=True)\n",
    "\n",
    "# Merge DataFrames on 'IDNUM'\n",
    "merged_df = pd.merge(df7, df5, on='IDNUM', suffixes=('_a', '_b'))\n",
    "\n",
    "# Filter for employees with salary greater than $40,000\n",
    "employees_over_40k = merged_df[merged_df['SALARY'] > 40000]\n",
    "\n",
    "# Format the 'SALARY' column as currency for display\n",
    "# Note: This converts the values to strings, so do this only for final display purposes\n",
    "employees_over_40k['SALARY'] = employees_over_40k['SALARY'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "# Display the filtered and formatted DataFrame\n",
    "print(\"Libname Sample 8: Employees with salary greater than $40,000\")\n",
    "employees_over_40k[['LNAME', 'FNAME', 'SALARY']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "\n",
    "# Ensure the necessary columns are not set as indexes\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "# Merge df1 with df2 on both FLIGHT and DATES\n",
    "merged_df1_2 = pd.merge(df1, df2, on=['FLIGHT', 'DATES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result with df3 on FLIGHT (assuming DELAY column is in df3)\n",
    "merged_all = pd.merge(merged_df1_2, df3, on=['FLIGHT'])\n",
    "\n",
    "# Filter for delayed flights (DELAY > 0)\n",
    "delayed_flights = merged_all[merged_all['DELAY'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>DATES_x</th>\n",
       "      <th>DEPART</th>\n",
       "      <th>ORIG_x</th>\n",
       "      <th>DEST_x</th>\n",
       "      <th>MILES</th>\n",
       "      <th>BOARDED_x</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ORIG_y</th>\n",
       "      <th>DEST_y</th>\n",
       "      <th>DELAYCAT</th>\n",
       "      <th>DESTYPE</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>DATES_y</th>\n",
       "      <th>DEST</th>\n",
       "      <th>BOARDED_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>366.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>366.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>366.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>366.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>366.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>44340.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>FRA</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>44340.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>FRA</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>44340.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>FRA</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>44340.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>FRA</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>44340.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>FRA</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLIGHT    DATES_x   DEPART ORIG_x DEST_x   MILES  BOARDED_x  CAPACITY  \\\n",
       "0      132 1998-03-01  56100.0    LGA    YYZ   366.0      115.0     178.0   \n",
       "1      132 1998-03-01  56100.0    LGA    YYZ   366.0      115.0     178.0   \n",
       "2      132 1998-03-01  56100.0    LGA    YYZ   366.0      115.0     178.0   \n",
       "3      132 1998-03-01  56100.0    LGA    YYZ   366.0      115.0     178.0   \n",
       "4      132 1998-03-01  56100.0    LGA    YYZ   366.0      115.0     178.0   \n",
       "..     ...        ...      ...    ...    ...     ...        ...       ...   \n",
       "165    622 1998-03-07  44340.0    LGA    FRA  3857.0      210.0     250.0   \n",
       "166    622 1998-03-07  44340.0    LGA    FRA  3857.0      210.0     250.0   \n",
       "167    622 1998-03-07  44340.0    LGA    FRA  3857.0      210.0     250.0   \n",
       "168    622 1998-03-07  44340.0    LGA    FRA  3857.0      210.0     250.0   \n",
       "169    622 1998-03-07  44340.0    LGA    FRA  3857.0      210.0     250.0   \n",
       "\n",
       "    ORIG_y DEST_y     DELAYCAT        DESTYPE  DELAY    DATES_y DEST  \\\n",
       "0      LGA    YYZ  11+ Minutes  International   14.0 1998-03-01  YYZ   \n",
       "1      LGA    YYZ  11+ Minutes  International   14.0 1998-03-02  YYZ   \n",
       "2      LGA    YYZ  11+ Minutes  International   14.0 1998-03-03  YYZ   \n",
       "3      LGA    YYZ  11+ Minutes  International   14.0 1998-03-04  YYZ   \n",
       "4      LGA    YYZ  11+ Minutes  International   14.0 1998-03-05  YYZ   \n",
       "..     ...    ...          ...            ...    ...        ...  ...   \n",
       "165    LGA    FRA  11+ Minutes  International   21.0 1998-03-02  FRA   \n",
       "166    LGA    FRA  11+ Minutes  International   21.0 1998-03-03  FRA   \n",
       "167    LGA    FRA  11+ Minutes  International   21.0 1998-03-04  FRA   \n",
       "168    LGA    FRA  11+ Minutes  International   21.0 1998-03-05  FRA   \n",
       "169    LGA    FRA  11+ Minutes  International   21.0 1998-03-07  FRA   \n",
       "\n",
       "     BOARDED_y  \n",
       "0        115.0  \n",
       "1        106.0  \n",
       "2         75.0  \n",
       "3        117.0  \n",
       "4        157.0  \n",
       "..         ...  \n",
       "165      176.0  \n",
       "166      180.0  \n",
       "167      137.0  \n",
       "168      185.0  \n",
       "169      210.0  \n",
       "\n",
       "[132 rows x 16 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delayed_flights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DATES'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m delayed_flights \u001b[38;5;241m=\u001b[39m merged_all[merged_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Select distinct rows and sort by DELAY in descending order\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Assuming DELAY column comes from one of the datasets (e.g., df1) without column name conflict\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# If there are conflicts, you might need suffixes in merges and adjust the column names accordingly\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m delayed_flights_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mdelayed_flights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFLIGHT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDELAY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLibname Sample 9a: Delayed International Flights in March\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m delayed_flights_sorted\n",
      "File \u001b[1;32mc:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DATES'] not in index\""
     ]
    }
   ],
   "source": [
    "# 9\n",
    "\n",
    "# Ensure the necessary columns are not set as indexes\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "# Merge df1 with df2 on both FLIGHT and DATES\n",
    "merged_df1_2 = pd.merge(df1, df2, on=['FLIGHT', 'DATES'])\n",
    "\n",
    "# Merge the result with df3 on FLIGHT (assuming DELAY column is in df3)\n",
    "merged_all = pd.merge(merged_df1_2, df3, on=['FLIGHT'])\n",
    "\n",
    "# Filter for delayed flights (DELAY > 0)\n",
    "delayed_flights = merged_all[merged_all['DELAY'] > 0]\n",
    "\n",
    "# Select distinct rows and sort by DELAY in descending order\n",
    "# Assuming DELAY column comes from one of the datasets (e.g., df1) without column name conflict\n",
    "# If there are conflicts, you might need suffixes in merges and adjust the column names accordingly\n",
    "delayed_flights_sorted = delayed_flights[['FLIGHT', 'DATES', 'DELAY']].drop_duplicates().sort_values(by='DELAY', ascending=False)\n",
    "\n",
    "print(\"Libname Sample 9a: Delayed International Flights in March\")\n",
    "delayed_flights_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 10: Payrolls 1 & 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>JOBCODE</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>BIRTH</th>\n",
       "      <th>HIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009</td>\n",
       "      <td>M</td>\n",
       "      <td>TA1</td>\n",
       "      <td>28880.0</td>\n",
       "      <td>1959-03-02</td>\n",
       "      <td>1992-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017</td>\n",
       "      <td>M</td>\n",
       "      <td>TA3</td>\n",
       "      <td>40858.0</td>\n",
       "      <td>1957-12-28</td>\n",
       "      <td>1981-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>F</td>\n",
       "      <td>TA3</td>\n",
       "      <td>39392.0</td>\n",
       "      <td>1965-05-19</td>\n",
       "      <td>1984-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1036</td>\n",
       "      <td>F</td>\n",
       "      <td>TA3</td>\n",
       "      <td>42465.0</td>\n",
       "      <td>1965-05-19</td>\n",
       "      <td>1984-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1036</td>\n",
       "      <td>F</td>\n",
       "      <td>TA3</td>\n",
       "      <td>42465.0</td>\n",
       "      <td>1965-05-19</td>\n",
       "      <td>1984-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1988</td>\n",
       "      <td>M</td>\n",
       "      <td>FA3</td>\n",
       "      <td>32217.0</td>\n",
       "      <td>1959-11-30</td>\n",
       "      <td>1984-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1991</td>\n",
       "      <td>F</td>\n",
       "      <td>TA1</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>1972-05-07</td>\n",
       "      <td>1992-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1995</td>\n",
       "      <td>F</td>\n",
       "      <td>ME1</td>\n",
       "      <td>28810.0</td>\n",
       "      <td>1973-08-24</td>\n",
       "      <td>1993-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1998</td>\n",
       "      <td>M</td>\n",
       "      <td>SCP</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>1970-09-10</td>\n",
       "      <td>1992-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1998</td>\n",
       "      <td>M</td>\n",
       "      <td>SCP</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>1970-09-10</td>\n",
       "      <td>1992-11-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDNUM SEX JOBCODE   SALARY      BIRTH      HIRED\n",
       "0    1009   M     TA1  28880.0 1959-03-02 1992-03-26\n",
       "1    1017   M     TA3  40858.0 1957-12-28 1981-10-16\n",
       "2    1036   F     TA3  39392.0 1965-05-19 1984-10-23\n",
       "148  1036   F     TA3  42465.0 1965-05-19 1984-10-23\n",
       "160  1036   F     TA3  42465.0 1965-05-19 1984-10-23\n",
       "..    ...  ..     ...      ...        ...        ...\n",
       "145  1988   M     FA3  32217.0 1959-11-30 1984-09-18\n",
       "146  1991   F     TA1  27645.0 1972-05-07 1992-12-12\n",
       "147  1995   F     ME1  28810.0 1973-08-24 1993-09-19\n",
       "159  1998   M     SCP  23100.0 1970-09-10 1992-11-02\n",
       "171  1998   M     SCP  23100.0 1970-09-10 1992-11-02\n",
       "\n",
       "[172 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10\n",
    "\n",
    "# For an accurate outer union correlation, ensure both DataFrames have the same columns\n",
    "# This step might involve adding missing columns as NaN in both DataFrames or adjusting as needed\n",
    "# Here, it's assumed that the necessary columns exist and are aligned\n",
    "\n",
    "# Perform the concatenation, equivalent to an outer union corr\n",
    "combined_df = pd.concat([df5[['IDNUM', 'SEX', 'JOBCODE', 'SALARY', 'BIRTH', 'HIRED']], df6], ignore_index=True)\n",
    "\n",
    "# Sort by the specified columns\n",
    "combined_df_sorted = combined_df.sort_values(by=['IDNUM', 'JOBCODE', 'SALARY'])\n",
    "\n",
    "# Assuming you want to print or display this DataFrame\n",
    "print(\"Libname Sample 10: Payrolls 1 & 2\")\n",
    "combined_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 12: AIRLINE.SAMDAT7 After Deleting Connecticut Employees\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>LNAME</th>\n",
       "      <th>FNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>HPHONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/586-7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017</td>\n",
       "      <td>WELCH</td>\n",
       "      <td>DARIUS</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/586-5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>WONG</td>\n",
       "      <td>LESLIE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/587-2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1050</td>\n",
       "      <td>TUTTLE</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>WHITE PLAINS</td>\n",
       "      <td>NY</td>\n",
       "      <td>914/455-2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1065</td>\n",
       "      <td>COPAS</td>\n",
       "      <td>FREDERICO</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1928</td>\n",
       "      <td>UPCHURCH</td>\n",
       "      <td>LARRY</td>\n",
       "      <td>WHITE PLAINS</td>\n",
       "      <td>NY</td>\n",
       "      <td>914/455-5009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1970</td>\n",
       "      <td>PARKER</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/383-3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1983</td>\n",
       "      <td>DEAN</td>\n",
       "      <td>SHARON</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1988</td>\n",
       "      <td>COOPER</td>\n",
       "      <td>ANTHONY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>212/587-1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1995</td>\n",
       "      <td>VARNER</td>\n",
       "      <td>ELIZABETH</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>718/384-7113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDNUM     LNAME      FNAME          CITY STATE        HPHONE\n",
       "0    1009    MORGAN     GEORGE      NEW YORK    NY  212/586-7753\n",
       "1    1017     WELCH     DARIUS      NEW YORK    NY  212/586-5535\n",
       "2    1036      WONG     LESLIE      NEW YORK    NY  212/587-2570\n",
       "5    1050    TUTTLE     THOMAS  WHITE PLAINS    NY  914/455-2119\n",
       "6    1065     COPAS  FREDERICO      NEW YORK    NY  718/384-5618\n",
       "..    ...       ...        ...           ...   ...           ...\n",
       "141  1928  UPCHURCH      LARRY  WHITE PLAINS    NY  914/455-5009\n",
       "143  1970    PARKER       ANNE      NEW YORK    NY  718/383-3895\n",
       "144  1983      DEAN     SHARON      NEW YORK    NY  718/384-1647\n",
       "145  1988    COOPER    ANTHONY      NEW YORK    NY  212/587-1228\n",
       "147  1995    VARNER  ELIZABETH      NEW YORK    NY  718/384-7113\n",
       "\n",
       "[104 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 12\n",
    "#Filter out rows where STATE equals 'CT'\n",
    "df7_filtered = df7[df7['STATE'] != 'CT']\n",
    "\n",
    "# Display the updated DataFrame, which excludes employees from Connecticut\n",
    "print(\"Libname Sample 12: AIRLINE.SAMDAT7 After Deleting Connecticut Employees\")\n",
    "df7_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 14: Number of Passengers per Flight by Date\n",
      "   FLIGHT DEST      DATES  BOARDED\n",
      "0     114  LAX 1998-03-01    172.0\n",
      "1     114  LAX 1998-03-02    119.0\n",
      "2     114  LAX 1998-03-03    197.0\n",
      "3     114  LAX 1998-03-04    178.0\n",
      "4     114  LAX 1998-03-05    117.0\n",
      "5     114  LAX 1998-03-06    128.0\n",
      "6     114  LAX 1998-03-07    160.0\n",
      "7     132  YYZ 1998-03-01    115.0\n",
      "8     132  YYZ 1998-03-02    106.0\n",
      "9     132  YYZ 1998-03-03     75.0\n",
      "10    132  YYZ 1998-03-04    117.0\n",
      "11    132  YYZ 1998-03-05    157.0\n",
      "12    132  YYZ 1998-03-06    150.0\n",
      "13    132  YYZ 1998-03-07    164.0\n",
      "14    202  ORD 1998-03-01    151.0\n",
      "15    202  ORD 1998-03-02    120.0\n",
      "16    202  ORD 1998-03-03    118.0\n",
      "17    202  ORD 1998-03-04    148.0\n",
      "18    202  ORD 1998-03-05    104.0\n",
      "19    202  ORD 1998-03-06    115.0\n",
      "20    202  ORD 1998-03-07    175.0\n",
      "21    219  LON 1998-03-01    198.0\n",
      "22    219  LON 1998-03-02    147.0\n",
      "23    219  LON 1998-03-03    197.0\n",
      "24    219  LON 1998-03-04    232.0\n",
      "25    219  LON 1998-03-05    160.0\n",
      "26    219  LON 1998-03-06    163.0\n",
      "27    219  LON 1998-03-07    241.0\n",
      "28    271  PAR 1998-03-01    138.0\n",
      "29    271  PAR 1998-03-02    104.0\n",
      "30    271  PAR 1998-03-03    147.0\n",
      "31    271  PAR 1998-03-04    146.0\n",
      "32    271  PAR 1998-03-05    177.0\n",
      "33    271  PAR 1998-03-07    155.0\n",
      "34    302  WAS 1998-03-01    105.0\n",
      "35    302  WAS 1998-03-02     78.0\n",
      "36    302  WAS 1998-03-03    123.0\n",
      "37    302  WAS 1998-03-04    115.0\n",
      "38    302  WAS 1998-03-06     66.0\n",
      "39    302  WAS 1998-03-07    135.0\n",
      "40    622  FRA 1998-03-01    207.0\n",
      "41    622  FRA 1998-03-02    176.0\n",
      "42    622  FRA 1998-03-03    180.0\n",
      "43    622  FRA 1998-03-04    137.0\n",
      "44    622  FRA 1998-03-05    185.0\n",
      "45    622  FRA 1998-03-07    210.0\n"
     ]
    }
   ],
   "source": [
    "#Sample 14 part 1\n",
    "\n",
    "# Group by FLIGHT and DATES, then sum up BOARDED\n",
    "passengers_per_flight_date = df1.groupby(['FLIGHT', 'DEST', 'DATES'])['BOARDED'].sum().reset_index()\n",
    "\n",
    "print(\"Libname Sample 14: Number of Passengers per Flight by Date\")\n",
    "print(passengers_per_flight_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 14: Maximum Number of Passengers per Flight\n",
      "  FLIGHT  BOARDED\n",
      "0    114    197.0\n",
      "1    132    164.0\n",
      "2    202    175.0\n",
      "3    219    241.0\n",
      "4    271    177.0\n",
      "5    302    135.0\n",
      "6    622    210.0\n"
     ]
    }
   ],
   "source": [
    "#Sample 14 part 2\n",
    "\n",
    "# Group by FLIGHT and calculate the max of BOARDED\n",
    "max_passengers_per_flight = df1.groupby('FLIGHT')['BOARDED'].max().reset_index()\n",
    "\n",
    "print(\"Libname Sample 14: Maximum Number of Passengers per Flight\")\n",
    "print(max_passengers_per_flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 15: Table Listing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 15 with glob\n",
    "# Specify the directory where your dataset files are stored, including a wildcard to match all files\n",
    "dataset_directory = 'C:/Users/comma/GitRepo/sas-access-samples/SAS Foundation/parquetdataset/'\n",
    "\n",
    "# Use glob.glob to list all files in the directory\n",
    "dataset_files = glob.glob(dataset_directory)\n",
    "\n",
    "# Print the list of dataset file names\n",
    "print(\"Libname Sample 15: Table Listing\")\n",
    "for file_path in dataset_files:\n",
    "    print(file_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 15: Table Listing\n",
      "samdat1\n",
      "samdat10\n",
      "samdat11\n",
      "samdat12\n",
      "samdat13\n",
      "samdat2\n",
      "samdat3\n",
      "samdat4\n",
      "samdat5\n",
      "samdat6\n",
      "samdat7\n",
      "samdat8\n",
      "samdat9\n"
     ]
    }
   ],
   "source": [
    "#Sample 15 with os\n",
    "# Specify the directory where your dataset files are stored\n",
    "dataset_directory = 'C:/Users/comma/GitRepo/sas-access-samples/SAS Foundation/parquetdataset/'\n",
    "\n",
    "# List all files in the directory\n",
    "dataset_files = os.listdir(dataset_directory)\n",
    "\n",
    "# Print the list of dataset file names\n",
    "print(\"Libname Sample 15: Table Listing\")\n",
    "for file in dataset_files:\n",
    "    print(file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 16: Contents of the SAMDAT2 Table\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   FLIGHT    46 non-null     object        \n",
      " 1   DATES     46 non-null     datetime64[ns]\n",
      " 2   ORIG      46 non-null     object        \n",
      " 3   DEST      46 non-null     object        \n",
      " 4   DELAYCAT  46 non-null     object        \n",
      " 5   DESTYPE   46 non-null     object        \n",
      " 6   DELAY     46 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(5)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sample 16\n",
    "# Display the title\n",
    "print(\"Libname Sample 16: Contents of the SAMDAT2 Table\")\n",
    "\n",
    "# Use the DataFrame.info() method to print information about df2\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 17: Ranking of Delayed Flights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>DATES</th>\n",
       "      <th>ORIG</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DELAYCAT</th>\n",
       "      <th>DESTYPE</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>RANKING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>11+ Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PAR</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>International</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1-10 Minutes</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>WAS</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>LGA</td>\n",
       "      <td>FRA</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>International</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLIGHT      DATES ORIG DEST      DELAYCAT        DESTYPE  DELAY  RANKING\n",
       "24    622 1998-03-04  LGA  FRA   11+ Minutes  International   30.0      1.0\n",
       "36    219 1998-03-06  LGA  LON   11+ Minutes  International   27.0      2.0\n",
       "42    622 1998-03-07  LGA  FRA   11+ Minutes  International   21.0      3.0\n",
       "2     219 1998-03-01  LGA  LON   11+ Minutes  International   18.0      4.0\n",
       "9     219 1998-03-02  LGA  LON   11+ Minutes  International   18.0      4.0\n",
       "41    219 1998-03-07  LGA  LON   11+ Minutes  International   15.0      6.0\n",
       "21    114 1998-03-04  LGA  LAX   11+ Minutes       Domestic   15.0      6.0\n",
       "4     132 1998-03-01  LGA  YYZ   11+ Minutes  International   14.0      8.0\n",
       "0     114 1998-03-01  LGA  LAX  1-10 Minutes       Domestic    8.0      9.0\n",
       "37    132 1998-03-06  LGA  YYZ  1-10 Minutes  International    7.0     10.0\n",
       "27    302 1998-03-04  LGA  WAS  1-10 Minutes       Domestic    7.0     10.0\n",
       "18    132 1998-03-03  LGA  YYZ  1-10 Minutes  International    6.0     12.0\n",
       "20    302 1998-03-03  LGA  WAS  1-10 Minutes       Domestic    5.0     13.0\n",
       "33    271 1998-03-05  LGA  PAR  1-10 Minutes  International    5.0     13.0\n",
       "11    132 1998-03-02  LGA  YYZ  1-10 Minutes  International    5.0     13.0\n",
       "8     202 1998-03-02  LGA  ORD  1-10 Minutes       Domestic    5.0     13.0\n",
       "5     271 1998-03-01  LGA  PAR  1-10 Minutes  International    5.0     13.0\n",
       "26    271 1998-03-04  LGA  PAR  1-10 Minutes  International    5.0     13.0\n",
       "16    219 1998-03-03  LGA  LON  1-10 Minutes  International    4.0     19.0\n",
       "44    271 1998-03-07  LGA  PAR  1-10 Minutes  International    4.0     19.0\n",
       "12    271 1998-03-02  LGA  PAR  1-10 Minutes  International    4.0     19.0\n",
       "32    132 1998-03-05  LGA  YYZ  1-10 Minutes  International    3.0     22.0\n",
       "30    219 1998-03-05  LGA  LON  1-10 Minutes  International    3.0     22.0\n",
       "23    219 1998-03-04  LGA  LON  1-10 Minutes  International    3.0     22.0\n",
       "29    202 1998-03-05  LGA  ORD  1-10 Minutes       Domestic    2.0     25.0\n",
       "19    271 1998-03-03  LGA  PAR  1-10 Minutes  International    2.0     25.0\n",
       "38    302 1998-03-06  LGA  WAS  1-10 Minutes       Domestic    1.0     27.0\n",
       "45    302 1998-03-07  LGA  WAS      No Delay       Domestic    0.0     28.0\n",
       "10    622 1998-03-02  LGA  FRA      No Delay  International    0.0     28.0\n",
       "13    302 1998-03-02  LGA  WAS      No Delay       Domestic    0.0     28.0\n",
       "7     114 1998-03-02  LGA  LAX      No Delay       Domestic    0.0     28.0\n",
       "15    202 1998-03-03  LGA  ORD      No Delay       Domestic   -1.0     32.0\n",
       "14    114 1998-03-03  LGA  LAX      No Delay       Domestic   -1.0     32.0\n",
       "34    114 1998-03-06  LGA  LAX      No Delay       Domestic   -1.0     32.0\n",
       "39    114 1998-03-07  LGA  LAX      No Delay       Domestic   -1.0     32.0\n",
       "43    132 1998-03-07  LGA  YYZ      No Delay  International   -2.0     36.0\n",
       "40    202 1998-03-07  LGA  ORD      No Delay       Domestic   -2.0     36.0\n",
       "6     302 1998-03-01  LGA  WAS      No Delay       Domestic   -2.0     36.0\n",
       "28    114 1998-03-05  LGA  LAX      No Delay       Domestic   -2.0     36.0\n",
       "17    622 1998-03-03  LGA  FRA      No Delay  International   -2.0     36.0\n",
       "35    202 1998-03-06  LGA  ORD      No Delay       Domestic   -3.0     41.0\n",
       "3     622 1998-03-01  LGA  FRA      No Delay  International   -5.0     42.0\n",
       "1     202 1998-03-01  LGA  ORD      No Delay       Domestic   -5.0     42.0\n",
       "25    132 1998-03-04  LGA  YYZ      No Delay  International   -5.0     42.0\n",
       "22    202 1998-03-04  LGA  ORD      No Delay       Domestic   -5.0     42.0\n",
       "31    622 1998-03-05  LGA  FRA      No Delay  International   -6.0     46.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample 17\n",
    "# Rank the DELAY column in descending order, handling ties by assigning the minimum rank in the group (equivalent to ties='low')\n",
    "df2['RANKING'] = df2['DELAY'].rank(method='min', ascending=False)\n",
    "\n",
    "# Sort the DataFrame based on the rank to make the printout more meaningful\n",
    "ranked_df = df2.sort_values(by='RANKING')\n",
    "\n",
    "# Optionally, you can format the DELAY column, though this step is purely for display purposes in SAS\n",
    "# In Pandas, formatting for display typically happens at the display/output level rather than changing the DataFrame\n",
    "\n",
    "# Display the DataFrame with formatted DELAY\n",
    "print(\"Libname Sample 17: Ranking of Delayed Flights\")\n",
    "#print(ranked_df[['DELAY', 'RANKING']].head())  # .head() to display the first few rows similar to PROC PRINT\n",
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 17a\n",
    "samtemp = df2.copy()\n",
    "\n",
    "# Mimicking the deletion of SAMTEMP\n",
    "del samtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 18: Number of Employees by Jobcode\n",
      "   JOBCODE   #\n",
      "8      BCK   9\n",
      "4      FA1  12\n",
      "2      FA2  16\n",
      "9      FA3   9\n",
      "12     ME1   8\n",
      "3      ME2  14\n",
      "10     ME3   9\n",
      "13     NA1   5\n",
      "15     NA2   3\n",
      "7      PT1   9\n",
      "5      PT2  10\n",
      "14     PT3   3\n",
      "11     SCP   8\n",
      "6      TA1   9\n",
      "0      TA2  20\n",
      "1      TA3  16\n"
     ]
    }
   ],
   "source": [
    "#Sample 18\n",
    "# Count the number of employees by JOBCODE\n",
    "employees_by_jobcode = df5['JOBCODE'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns to match the expected output\n",
    "employees_by_jobcode.columns = ['JOBCODE', '#']\n",
    "\n",
    "# Sort by JOBCODE to mimic the default behavior of proc tabulate\n",
    "employees_by_jobcode.sort_values(by='JOBCODE', inplace=True)\n",
    "\n",
    "# Display the title\n",
    "print(\"Libname Sample 18: Number of Employees by Jobcode\")\n",
    "\n",
    "# Display the results\n",
    "print(employees_by_jobcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 19: SAMDAT5 After Appending SAMDAT6\n",
      "    IDNUM SEX JOBCODE   SALARY      BIRTH      HIRED\n",
      "0    1009   M     TA1  28880.0 1959-03-02 1992-03-26\n",
      "1    1017   M     TA3  40858.0 1957-12-28 1981-10-16\n",
      "2    1036   F     TA3  39392.0 1965-05-19 1984-10-23\n",
      "3    1037   F     TA1  28558.0 1964-04-10 1992-09-13\n",
      "4    1038   F     TA1  26533.0 1969-11-09 1991-11-23\n",
      "..    ...  ..     ...      ...        ...        ...\n",
      "167  1369   M     TA3  36598.0 1961-12-28 1987-03-13\n",
      "168  1447   F     FA1  22123.0 1972-08-07 1992-10-29\n",
      "169  1561   M     TA3  36514.0 1963-11-30 1987-10-07\n",
      "170  1639   F     TA3  42260.0 1957-06-26 1984-01-28\n",
      "171  1998   M     SCP  23100.0 1970-09-10 1992-11-02\n",
      "\n",
      "[172 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sample 19\n",
    "# Append df6 to df5\n",
    "df5_appended = pd.concat([df5, df6], ignore_index=True)\n",
    "\n",
    "# Display the title\n",
    "print(\"Libname Sample 19: SAMDAT5 After Appending SAMDAT6\")\n",
    "\n",
    "# Display the appended DataFrame\n",
    "# Note: In a script, you might print a subset of rows to avoid overwhelming the console\n",
    "print(df5_appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 20: Invoice Frequency by Country\n",
      "     COUNTRY  FREQUENCY\n",
      "0        USA         10\n",
      "1     Brazil          4\n",
      "2  Argentina          2\n",
      "3  Australia          1\n"
     ]
    }
   ],
   "source": [
    "# Sample 20\n",
    "# Keep only the INVNUM and COUNTRY columns, similar to the SAS keep= option\n",
    "df9_filtered = df9[['INVNUM', 'COUNTRY']]\n",
    "\n",
    "# Calculate the frequency of each country\n",
    "country_frequency = df9_filtered['COUNTRY'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns to make the output clearer\n",
    "country_frequency.columns = ['COUNTRY', 'FREQUENCY']\n",
    "\n",
    "# Display the title\n",
    "print(\"Libname Sample 20: Invoice Frequency by Country\")\n",
    "\n",
    "# Display the frequency table\n",
    "print(country_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 21: High Bills--Not Paid\n",
      "Column Labels: AMTINUS=amountinus, BILLEDON=billedon, INVNUM=invoicenum, BILLEDTO=billedto\n",
      "    INVNUM  BILLEDTO         AMTINUS   BILLEDON\n",
      "1  11271.0  18543489  $11,063,836.00 1998-10-05\n"
     ]
    }
   ],
   "source": [
    "# Sample 21\n",
    "\n",
    "allinv = df9[['PAIDON', 'BILLEDON', 'INVNUM', 'AMTINUS', 'BILLEDTO']].head(5)\n",
    "notpaid = allinv[pd.isna(allinv['PAIDON']) & (allinv['AMTINUS'] >= 300000.00)].copy()\n",
    "notpaid = notpaid[['INVNUM', 'BILLEDTO', 'AMTINUS', 'BILLEDON']]\n",
    "# Format the AMTINUS column for display\n",
    "notpaid['AMTINUS'] = notpaid['AMTINUS'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "# Print the DataFrame with labels as a description\n",
    "print(\"Libname Sample 21: High Bills--Not Paid\")\n",
    "print(\"Column Labels: AMTINUS=amountinus, BILLEDON=billedon, INVNUM=invoicenum, BILLEDTO=billedto\")\n",
    "print(notpaid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 22: Interns Who Are Family Members of Employees\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LASTNAME</th>\n",
       "      <th>FIRSTNAME</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>FAMILYID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>HIREDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>765112.0</td>\n",
       "      <td>234967.0</td>\n",
       "      <td>M</td>\n",
       "      <td>CSR010</td>\n",
       "      <td>1998-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NISHIMATSU-LYNCH</td>\n",
       "      <td>RICHARD</td>\n",
       "      <td>765111.0</td>\n",
       "      <td>677890.0</td>\n",
       "      <td>M</td>\n",
       "      <td>CSR011</td>\n",
       "      <td>1998-05-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LASTNAME FIRSTNAME     EMPID  FAMILYID GENDER    DEPT   HIREDATE\n",
       "0             SMITH    ROBERT  765112.0  234967.0      M  CSR010 1998-05-04\n",
       "1  NISHIMATSU-LYNCH   RICHARD  765111.0  677890.0      M  CSR011 1998-05-04"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample 22\n",
    "emp_csr = df10[df10['DEPT'].isin(['CSR010', 'CSR011', 'CSR004'])]\n",
    "family_members = pd.merge(emp_csr, df13, left_on='EMPID', right_on='FAMILYID', how='inner')\n",
    "# Select specific columns and rename them to match SAS output with all caps\n",
    "#family_members\n",
    "result = family_members[['LASTNAME_y', 'FIRSTNAM', 'EMPID_y', 'FAMILYID',  'GENDER_y', 'DEPT_y', 'HIREDATE_y']]\n",
    "result.columns = ['LASTNAME', 'FIRSTNAME', 'EMPID', 'FAMILYID', 'GENDER', 'DEPT', 'HIREDATE']\n",
    "# Capitalize all column names\n",
    "result.columns = [col.upper() for col in result.columns]\n",
    "# Display results\n",
    "print(\"Libname Sample 22: Interns Who Are Family Members of Employees\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FLIGHT      DATES ORIG DEST\n",
      "34    302 1998-03-01  LGA  WAS\n",
      "35    302 1998-03-02  LGA  WAS\n",
      "36    302 1998-03-03  LGA  WAS\n",
      "37    302 1998-03-04  LGA  WAS\n",
      "38    302 1998-03-06  LGA  WAS\n",
      "39    302 1998-03-07  LGA  WAS\n"
     ]
    }
   ],
   "source": [
    "#Sample 23\n",
    "flight_df = df1[df1['DEST'] == 'WAS'][['FLIGHT', 'DATES', 'ORIG', 'DEST']]\n",
    "print (flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 9a: Delayed International Flights in March\n",
      "    FLIGHT    DATES_x   DEPART ORIG_from_df1 DEST_from_df1   MILES  BOARDED_x  \\\n",
      "157    622 1998-03-04  44340.0           LGA           FRA  3857.0      137.0   \n",
      "156    622 1998-03-04  44340.0           LGA           FRA  3857.0      137.0   \n",
      "155    622 1998-03-04  44340.0           LGA           FRA  3857.0      137.0   \n",
      "154    622 1998-03-04  44340.0           LGA           FRA  3857.0      137.0   \n",
      "153    622 1998-03-04  44340.0           LGA           FRA  3857.0      137.0   \n",
      "..     ...        ...      ...           ...           ...     ...        ...   \n",
      "113    271 1998-03-03  47820.0           LGA           PAR  3635.0      147.0   \n",
      "112    271 1998-03-03  47820.0           LGA           PAR  3635.0      147.0   \n",
      "111    271 1998-03-03  47820.0           LGA           PAR  3635.0      147.0   \n",
      "110    271 1998-03-03  47820.0           LGA           PAR  3635.0      147.0   \n",
      "115    271 1998-03-03  47820.0           LGA           PAR  3635.0      147.0   \n",
      "\n",
      "     CAPACITY ORIG_from_df2 DEST_from_df2      DELAYCAT        DESTYPE  DELAY  \\\n",
      "157     250.0           LGA           FRA   11+ Minutes  International   30.0   \n",
      "156     250.0           LGA           FRA   11+ Minutes  International   30.0   \n",
      "155     250.0           LGA           FRA   11+ Minutes  International   30.0   \n",
      "154     250.0           LGA           FRA   11+ Minutes  International   30.0   \n",
      "153     250.0           LGA           FRA   11+ Minutes  International   30.0   \n",
      "..        ...           ...           ...           ...            ...    ...   \n",
      "113     250.0           LGA           PAR  1-10 Minutes  International    2.0   \n",
      "112     250.0           LGA           PAR  1-10 Minutes  International    2.0   \n",
      "111     250.0           LGA           PAR  1-10 Minutes  International    2.0   \n",
      "110     250.0           LGA           PAR  1-10 Minutes  International    2.0   \n",
      "115     250.0           LGA           PAR  1-10 Minutes  International    2.0   \n",
      "\n",
      "       DATES_y DEST  BOARDED_y  \n",
      "157 1998-03-07  FRA      210.0  \n",
      "156 1998-03-05  FRA      185.0  \n",
      "155 1998-03-04  FRA      137.0  \n",
      "154 1998-03-03  FRA      180.0  \n",
      "153 1998-03-02  FRA      176.0  \n",
      "..         ...  ...        ...  \n",
      "113 1998-03-04  PAR      146.0  \n",
      "112 1998-03-03  PAR      147.0  \n",
      "111 1998-03-02  PAR      172.0  \n",
      "110 1998-03-01  PAR      138.0  \n",
      "115 1998-03-07  PAR      155.0  \n",
      "\n",
      "[132 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "#Sample 9\n",
    "# Merge df1 with df2 on FLIGHT and DATES\n",
    "# merged_df1_2 = pd.merge(df1, df2, on=['FLIGHT', 'DATES'])\n",
    "merged_df1_2 = pd.merge(df1, df2, on=['FLIGHT', 'DATES'], suffixes=('_from_df1', '_from_df2'))\n",
    "\n",
    "# Merge the result with df3 on FLIGHT (assuming DELAY column is in df1 or df3, adjust accordingly)\n",
    "merged_all = pd.merge(merged_df1_2, df3, on='FLIGHT')\n",
    "\n",
    "# Filter for delayed flights (DELAY > 0)\n",
    "delayed_flights = merged_all[merged_all['DELAY'] > 0].drop_duplicates()\n",
    "\n",
    "# Order the results by DELAY in descending order\n",
    "delayed_flights_sorted = delayed_flights.sort_values(by='DELAY', ascending=False)\n",
    "print(\"Libname Sample 9a: Delayed International Flights in March\")\n",
    "#print(delayed_flights_sorted[['FLIGHT', 'DATES', 'DELAY']])\n",
    "#print(merged_df1_2)\n",
    "#print(merged_all)\n",
    "#print(\"Columns in merged_all:\", merged_all.columns)\n",
    "#print(delayed_flights)\n",
    "print(delayed_flights_sorted) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 9a: Delayed International Flights in March\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>DATES</th>\n",
       "      <th>DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>622</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-02</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>219</td>\n",
       "      <td>1998-03-04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>132</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202</td>\n",
       "      <td>1998-03-05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>271</td>\n",
       "      <td>1998-03-03</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>302</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLIGHT      DATES  DELAY\n",
       "43    622 1998-03-04   30.0\n",
       "26    219 1998-03-06   27.0\n",
       "45    622 1998-03-07   21.0\n",
       "21    219 1998-03-01   18.0\n",
       "22    219 1998-03-02   18.0\n",
       "27    219 1998-03-07   15.0\n",
       "3     114 1998-03-04   15.0\n",
       "7     132 1998-03-01   14.0\n",
       "0     114 1998-03-01    8.0\n",
       "12    132 1998-03-06    7.0\n",
       "37    302 1998-03-04    7.0\n",
       "9     132 1998-03-03    6.0\n",
       "8     132 1998-03-02    5.0\n",
       "28    271 1998-03-01    5.0\n",
       "15    202 1998-03-02    5.0\n",
       "31    271 1998-03-04    5.0\n",
       "32    271 1998-03-05    5.0\n",
       "36    302 1998-03-03    5.0\n",
       "23    219 1998-03-03    4.0\n",
       "29    271 1998-03-02    4.0\n",
       "33    271 1998-03-07    4.0\n",
       "25    219 1998-03-05    3.0\n",
       "24    219 1998-03-04    3.0\n",
       "11    132 1998-03-05    3.0\n",
       "18    202 1998-03-05    2.0\n",
       "30    271 1998-03-03    2.0\n",
       "38    302 1998-03-06    1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 9\n",
    "# Merge df1 with df2 on both 'FLIGHT' and 'DATES'\n",
    "merged_df1_2 = pd.merge(df1, df2, on=['FLIGHT', 'DATES'], how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Merge the result with df3 on both 'FLIGHT' and 'DATES'\n",
    "merged_all = pd.merge(merged_df1_2, df3, on=['FLIGHT', 'DATES'], how='outer', suffixes=('_df12', '_df3'))\n",
    "\n",
    "# Assuming DELAY is from df1 and correctly included in merged_all\n",
    "delayed_flights = merged_all[merged_all['DELAY'] > 0].drop_duplicates()\n",
    "\n",
    "# Sort by 'DELAY' in descending order\n",
    "delayed_flights_sorted = delayed_flights.sort_values(by='DELAY', ascending=False)\n",
    "\n",
    "print(\"Libname Sample 9a: Delayed International Flights in March\")\n",
    "#print(delayed_flights_sorted[['FLIGHT', 'DATES', 'DELAY']])\n",
    "delayed_flights_sorted[['FLIGHT', 'DATES', 'DELAY']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24536\\524297637.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnew_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'EMPID'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1588\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STATE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'NY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CODE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'FA'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnew_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'EMPID'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'1588'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STATE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'NY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CODE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'FA'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdf8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         ):\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Sample 11\n",
    "\n",
    "enginename = \"ASTER\" \n",
    "\n",
    "df8.columns = ['EMPID', 'STATE', 'CODE']\n",
    "\n",
    "# Check the engine condition and insert data accordingly\n",
    "if enginename == 'ASTER':\n",
    "    new_row = {'EMPID': 1588, 'STATE': 'NY', 'CODE': 'FA'}\n",
    "else:\n",
    "    new_row = {'EMPID': '1588', 'STATE': 'NY', 'CODE': 'FA'}\n",
    "\n",
    "df8 = df8.append(new_row, ignore_index=True)\n",
    "print(df8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files (x86)/Python312-32/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "enginename = \"ASTER\"  # This would be set based on your application's logic or configuration\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df8 represents SAMDAT8 and is already initialized elsewhere in your code\n",
    "# Example initialization if not already done:\n",
    "# df8 = pd.DataFrame(columns=['EMPID', 'STATE', 'CODE'])\n",
    "df8.columns = ['EMPID', 'STATE', 'CODE']\n",
    "# Check the engine condition and insert data accordingly\n",
    "if enginename == 'ASTER':\n",
    "    new_row = {'EMPID': 1588, 'STATE': 'NY', 'CODE': 'FA'}\n",
    "else:\n",
    "    new_row = {'EMPID': '1588', 'STATE': 'NY', 'CODE': 'FA'}\n",
    "\n",
    "# Append the row to the DataFrame\n",
    "df8 = df8.append(new_row, ignore_index=True)\n",
    "\n",
    "# Capitalize column names\n",
    "df8.columns = [col.upper() for col in df8.columns]\n",
    "\n",
    "# Display the DataFrame with a title\n",
    "print(\"Libname Sample 11: New Row in AIRLINE.SAMDAT8\")\n",
    "print(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EMPID STATE CODE\n",
      "0   1106    CT   PT\n",
      "1   1118    NY   PT\n",
      "2   1126    NY   TA\n",
      "3   1352    NY   NA\n",
      "4   1385    CT   ME\n",
      "5   1401    NJ   TA\n",
      "6   1405    NJ   SC\n",
      "7   1417    NJ   NA\n",
      "8   1420    NJ   ME\n",
      "9   1431    CT   FA\n",
      "10  1433    NJ   FA\n",
      "11  1442    NJ   PT\n",
      "12  1564    NY   SC\n",
      "13  1639    CT   TA\n",
      "14  1677    CT   BC\n",
      "15  1834    NY   BC\n",
      "16  1882    NY   ME\n",
      "17  1935    CT   NA\n",
      "18  1983    NY   FA\n",
      "19  1588    NY   FA\n",
      "20  1588    NY   FA\n"
     ]
    }
   ],
   "source": [
    "# Find indices of rows where EMPID equals 1588\n",
    "indices_to_drop = df8[df8['EMPID'] == 1588].index\n",
    "\n",
    "# Drop these rows from the DataFrame\n",
    "df8.drop(indices_to_drop, inplace=True)\n",
    "print(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 11: New Row in AIRLINE.SAMDAT8\n",
      "   EMPID STATE CODE\n",
      "0   1106    CT   PT\n",
      "1   1118    NY   PT\n",
      "2   1126    NY   TA\n",
      "3   1352    NY   NA\n",
      "4   1385    CT   ME\n",
      "5   1401    NJ   TA\n",
      "6   1405    NJ   SC\n",
      "7   1417    NJ   NA\n",
      "8   1420    NJ   ME\n",
      "9   1431    CT   FA\n",
      "10  1433    NJ   FA\n",
      "11  1442    NJ   PT\n",
      "12  1564    NY   SC\n",
      "13  1639    CT   TA\n",
      "14  1677    CT   BC\n",
      "15  1834    NY   BC\n",
      "16  1882    NY   ME\n",
      "17  1935    CT   NA\n",
      "18  1983    NY   FA\n",
      "19  1588    NY   FA\n",
      "20  1588    NY   FA\n",
      "21  1588    NY   FA\n"
     ]
    }
   ],
   "source": [
    "#Sample 11\n",
    "enginename = \"ASTER\"  # This would be set based on your application's logic or configuration\n",
    "\n",
    "# df8 = pd.DataFrame(columns=['EMPID', 'STATE', 'CODE'])\n",
    "df8.columns = ['EMPID', 'STATE', 'CODE']\n",
    "# Check the engine condition and insert data accordingly\n",
    "if enginename == 'ASTER':\n",
    "    new_row = pd.DataFrame({'EMPID': [1588], 'STATE': ['NY'], 'CODE': ['FA']})\n",
    "else:\n",
    "    new_row = pd.DataFrame({'EMPID': ['1588'], 'STATE': ['NY'], 'CODE': ['FA']})\n",
    "\n",
    "# Use pd.concat to add the new row to df8\n",
    "df8 = pd.concat([df8, new_row], ignore_index=True)\n",
    "\n",
    "# Capitalize column names\n",
    "df8.columns = [col.upper() for col in df8.columns]\n",
    "\n",
    "# Display the DataFrame with a title\n",
    "print(\"Libname Sample 11: New Row in AIRLINE.SAMDAT8\")\n",
    "print(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 13\n",
    "\n",
    "# Perform an inner join\n",
    "merged_df = pd.merge(df7, df5, on='IDNUM', suffixes=('_a', '_b'))\n",
    "\n",
    "# Filter for employees with a salary greater than $40,000\n",
    "high_earners = merged_df[merged_df['SALARY'] > 40000]\n",
    "\n",
    "# Select and rename columns\n",
    "high_earners = high_earners[['LNAME', 'FNAME', 'SALARY']]\n",
    "high_earners.rename(columns={'LNAME': 'LASTNAME', 'FNAME': 'FIRSTNAME', 'SALARY': 'SALARY'}, inplace=True)\n",
    "\n",
    "# Format the SALARY column for display as currency\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libname Sample 13: Employees with salaries over $40,000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LASTNAME</th>\n",
       "      <th>FIRSTNAME</th>\n",
       "      <th>SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELCH</td>\n",
       "      <td>DARIUS</td>\n",
       "      <td>$40,858.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WONG</td>\n",
       "      <td>LESLIE</td>\n",
       "      <td>$42,465.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VENTER</td>\n",
       "      <td>RANDALL</td>\n",
       "      <td>$66,558.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VENTER</td>\n",
       "      <td>RANDALL</td>\n",
       "      <td>$69,742.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MARSHBURN</td>\n",
       "      <td>JASPER</td>\n",
       "      <td>$89,632.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MARSHBURN</td>\n",
       "      <td>JASPER</td>\n",
       "      <td>$94,039.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>THOMPSON</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>$89,977.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RHODES</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>$40,586.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DENNIS</td>\n",
       "      <td>ROGER</td>\n",
       "      <td>$111,379.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KIMANI</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>$40,899.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CASTON</td>\n",
       "      <td>FRANKLIN</td>\n",
       "      <td>$41,690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>STEPHENSON</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>$42,178.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BANADYGA</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>$88,606.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>O'NEAL</td>\n",
       "      <td>BRYAN</td>\n",
       "      <td>$40,079.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RIVERS</td>\n",
       "      <td>SIMON</td>\n",
       "      <td>$53,798.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>MORGAN</td>\n",
       "      <td>ALFRED</td>\n",
       "      <td>$42,264.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RAYNOR</td>\n",
       "      <td>MILTON</td>\n",
       "      <td>$43,900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>COHEN</td>\n",
       "      <td>LEE</td>\n",
       "      <td>$91,376.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>GREGORSKI</td>\n",
       "      <td>DANIEL</td>\n",
       "      <td>$68,096.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>HAVELKA</td>\n",
       "      <td>RAYMOND</td>\n",
       "      <td>$41,551.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>HARRIS</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>$84,685.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>$52,270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ROUSE</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>$43,071.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRADY</td>\n",
       "      <td>CHRISTINE</td>\n",
       "      <td>$68,767.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>HASENHAUER</td>\n",
       "      <td>CHRISTINA</td>\n",
       "      <td>$70,736.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NEWKIRK</td>\n",
       "      <td>SANDRA</td>\n",
       "      <td>$84,536.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>WELLS</td>\n",
       "      <td>AGNES</td>\n",
       "      <td>$42,274.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NEWTON</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>$84,203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BAREFOOT</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>$43,025.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>PARKER</td>\n",
       "      <td>JAY</td>\n",
       "      <td>$41,526.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>HERRERO</td>\n",
       "      <td>CLYDE</td>\n",
       "      <td>$66,130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>PENNINGTON</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>$71,349.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>CARTER-COHEN</td>\n",
       "      <td>KAREN</td>\n",
       "      <td>$40,260.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>CARTER-COHEN</td>\n",
       "      <td>KAREN</td>\n",
       "      <td>$42,260.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>BRANCACCIO</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>$66,517.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>LUFKIN</td>\n",
       "      <td>ROY</td>\n",
       "      <td>$109,630.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>TRIPP</td>\n",
       "      <td>KATHY</td>\n",
       "      <td>$84,471.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NORRIS</td>\n",
       "      <td>DIANE</td>\n",
       "      <td>$43,433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>TUCKER</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>$41,538.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>STEPHENSON</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>$91,908.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>GRAHAM</td>\n",
       "      <td>ALVIN</td>\n",
       "      <td>$65,111.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>UPCHURCH</td>\n",
       "      <td>LARRY</td>\n",
       "      <td>$89,858.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>FERNANDEZ</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>$51,081.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LASTNAME  FIRSTNAME       SALARY\n",
       "1           WELCH     DARIUS   $40,858.00\n",
       "3            WONG     LESLIE   $42,465.00\n",
       "9          VENTER    RANDALL   $66,558.00\n",
       "10         VENTER    RANDALL   $69,742.00\n",
       "18      MARSHBURN     JASPER   $89,632.00\n",
       "19      MARSHBURN     JASPER   $94,039.00\n",
       "20       THOMPSON      WAYNE   $89,977.00\n",
       "21         RHODES     JEREMY   $40,586.00\n",
       "28         DENNIS      ROGER  $111,379.00\n",
       "36         KIMANI       ANNE   $40,899.00\n",
       "51         CASTON   FRANKLIN   $41,690.00\n",
       "53     STEPHENSON       ADAM   $42,178.00\n",
       "54       BANADYGA     JUSTIN   $88,606.00\n",
       "55         O'NEAL      BRYAN   $40,079.00\n",
       "58         RIVERS      SIMON   $53,798.00\n",
       "64         MORGAN     ALFRED   $42,264.00\n",
       "66         RAYNOR     MILTON   $43,900.00\n",
       "73          COHEN        LEE   $91,376.00\n",
       "76      GREGORSKI     DANIEL   $68,096.00\n",
       "78        HAVELKA    RAYMOND   $41,551.00\n",
       "79         HARRIS    CHARLES   $84,685.00\n",
       "85        NEWKIRK    WILLIAM   $52,270.00\n",
       "87          ROUSE     JEREMY   $43,071.00\n",
       "95          BRADY  CHRISTINE   $68,767.00\n",
       "106    HASENHAUER  CHRISTINA   $70,736.00\n",
       "109       NEWKIRK     SANDRA   $84,536.00\n",
       "110         WELLS      AGNES   $42,274.00\n",
       "114        NEWTON      JAMES   $84,203.00\n",
       "117      BAREFOOT     JOSEPH   $43,025.00\n",
       "118        PARKER        JAY   $41,526.00\n",
       "119       HERRERO      CLYDE   $66,130.00\n",
       "121    PENNINGTON    MICHAEL   $71,349.00\n",
       "127  CARTER-COHEN      KAREN   $40,260.00\n",
       "128  CARTER-COHEN      KAREN   $42,260.00\n",
       "135    BRANCACCIO     JOSEPH   $66,517.00\n",
       "136        LUFKIN        ROY  $109,630.00\n",
       "139         TRIPP      KATHY   $84,471.00\n",
       "141        NORRIS      DIANE   $43,433.00\n",
       "144        TUCKER       ALAN   $41,538.00\n",
       "145    STEPHENSON     ROBERT   $91,908.00\n",
       "147        GRAHAM      ALVIN   $65,111.00\n",
       "151      UPCHURCH      LARRY   $89,858.00\n",
       "152     FERNANDEZ    KATRINA   $51,081.00"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 13\n",
    "\n",
    "# Perform an inner join\n",
    "merged_df = pd.merge(df7, df5, on='IDNUM')\n",
    "\n",
    "# Filter for employees with a salary greater than $40,000\n",
    "high_earners = merged_df[merged_df['SALARY'] > 40000]\n",
    "\n",
    "# Select and rename columns\n",
    "high_earners = high_earners[['LNAME', 'FNAME', 'SALARY']]\n",
    "high_earners.rename(columns={'LNAME': 'LASTNAME', 'FNAME': 'FIRSTNAME', 'SALARY': 'SALARY'}, inplace=True)\n",
    "\n",
    "# Format the SALARY column for display as currency\n",
    "high_earners['SALARY'] = high_earners['SALARY'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Libname Sample 13: Employees with salaries over $40,000\")\n",
    "high_earners\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
